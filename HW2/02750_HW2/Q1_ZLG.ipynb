{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "controversial-universe",
   "metadata": {},
   "source": [
    "## Question 1. ZLG algorithm implementation (50 points)\n",
    "You are to implement the ZLG algorithem for this problem. We will use a subset of multiclass data where the label is a protein subcellular localization. The 8 features are extracted from the protein sequence. For this problem we are only using points with labels 'MIT' or 'NUC'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-character",
   "metadata": {},
   "source": [
    "First, read the paper and answer the following questions.\n",
    "#### 1. What is the idea behind the ZLG algorithm (5 points)?\n",
    "#### 2. What are the assumptions behind the ZLG algorithm (5 points)?\n",
    "#### 3. What are the pros and cons of the ZLG algorithm (5points)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-commission",
   "metadata": {},
   "source": [
    "A total of 892 data points have labels 'MIT' (244) or 'NUC' (429). We start with the labels of only the first 200 data points (set Y_k). The other 792 points are in Y_u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data.csv')\n",
    "data_CYTNUC = data.loc[data['Label'].isin(['MIT','NUC'])].values\n",
    "X = data_CYTNUC[:,:8]\n",
    "y = LabelEncoder().fit_transform(data_CYTNUC[:,-1])\n",
    "\n",
    "n_l = 200\n",
    "\n",
    "Xk = X[:n_l,:]\n",
    "Yk = y[:n_l]\n",
    "Xu = X[n_l:,:]\n",
    "Yu = y[n_l:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-philippines",
   "metadata": {},
   "source": [
    "(5 points) Let's first construct the weight matrix W. Use t = 0, $\\sigma$ as the standard deviation of X. Then calculate the D matrix and the Laplacian matrix (Delta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-spectacular",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Laplacian_matrix(X):\n",
    "    ## TODO ##\n",
    "    \n",
    "    return Delta\n",
    "\n",
    "Delta = Laplacian_matrix(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-handbook",
   "metadata": {},
   "source": [
    "(5 points) Now complete the subroutine to compute the minimum-energy solution for the unlabeled instances. (Hint: Use the formula in page 38, Lecture 7.) The function also outputs one submatrix that we will use to select points to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_energy_solution(Delta,n_l,fl):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Delta: The Laplacian matrix. \n",
    "        n_l: Number of labeled points. Notice that Delta should have the upper left submatrix \n",
    "            corresponding to these n_l points. So when new points get labeled, you may need \n",
    "            to rearrange the matrix.\n",
    "        fl: Known labels.\n",
    "    Returns:\n",
    "        Delta_uu_inv: Inverse matrix of the submatrix corresponding to unlabeled points.\n",
    "        fu: Minimum energy solution of all unlabeled points.\n",
    "    \"\"\"\n",
    "    ## TODO ##\n",
    "    \n",
    "    return Delta_uu_inv, fu\n",
    "\n",
    "Delta_uu_inv, fu = minimum_energy_solution(Delta,n_l,Yk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-adoption",
   "metadata": {},
   "source": [
    "(15 points) We would like to query the points that minimize the expected risk. To do so, we want to be able to calculate the expected estimated risk after querying any point k. The variable Rhat_fplus_xk refers to $\\hat{R}(f^{+x_k})$. fu_xk0 is $f_u^{+(x_k,0)}$ and vice versa for fu_xk1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_estimated_risk(Delta_uu_inv,k,fu):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Delta_uu_inv: Inverse matrix of the submatrix corresponding to unlabeled points.\n",
    "        k: index of one unlabeled point with respect to the uu submatrix (not the entire Delta)\n",
    "        fu: Minimum energy solution of all unlabeled points.\n",
    "    Returns:\n",
    "        Rhat_fplus_xk: Expected estimated risk after querying node k\n",
    "    \"\"\"\n",
    "    ## fu plus xk, yk = 0\n",
    "    fu_xk0 = fu + (0 - fu[k])*Delta_uu_inv[:,k]/Delta_uu_inv[k,k]\n",
    "    ## fu plus xk, yk = 1\n",
    "    fu_xk1 = fu + (1 - fu[k])*Delta_uu_inv[:,k]/Delta_uu_inv[k,k]\n",
    "    \n",
    "    ## TODO ##\n",
    "    \n",
    "    return Rhat_fplus_xk\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-bridal",
   "metadata": {},
   "source": [
    "(5 points) Compute the above expected estimated risk for all unlabeled points and select one to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zlg_query(Delta_uu_inv,n_l,fu,n_samples):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Delta_uu_inv: Inverse matrix of the submatrix corresponding to unlabeled points.\n",
    "        n_l: Number of labeled points.\n",
    "        fu: Minimum energy solution of all unlabeled points.\n",
    "        n_samples: Number of samples.\n",
    "    Returns:\n",
    "        query_idx: the idx of the point to query, wrt the unlabeled points \n",
    "                (idx is 0 if it's the first unlabeled point)\n",
    "    \"\"\"\n",
    "    n_u = n_samples - n_l\n",
    "    query_idx = 0\n",
    "    min_Rhat = np.inf\n",
    "    ## TODO ##\n",
    "    \n",
    "    return query_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-husband",
   "metadata": {},
   "source": [
    "Let's try query 100 points. Which points are queried? Compare with random queries and make a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = X.shape[0]\n",
    "for t in range(100):\n",
    "    ## edit this block ##\n",
    "    query_idx = zlg_query(Delta_uu_inv,n_l,fu,n_samples)\n",
    "    Yk = np.append(Yk,Yu[query_idx])\n",
    "    Yu = np.delete(Yu,query_idx)\n",
    "    Xk = np.append(Xk,[Xu[query_idx,:]],axis=0)\n",
    "    Xu = np.delete(Xu,query_idx, 0)\n",
    "    n_l += 1\n",
    "    Delta = Laplacian_matrix(np.concatenate((Xk,Xu),axis=0))\n",
    "    Delta_uu_inv, fu = minimum_energy_solution(Delta,n_l,Yk)\n",
    "    print(query_idx)\n",
    "    ## TODO ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-restaurant",
   "metadata": {},
   "source": [
    "Bonus question (Your grade will not exceed 100 for this homework): For this dataset, how many labeled data points do you actually need, to train the model sufficiently well? And why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
