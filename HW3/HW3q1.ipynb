{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern,RBF,WhiteKernel,DotProduct\n",
    "from sklearn.metrics import r2_score\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "from modAL.models import BayesianOptimizer, ActiveLearner, CommitteeRegressor\n",
    "from modAL.acquisition import max_EI\n",
    "from modAL.disagreement import max_std_sampling, max_disagreement_sampling\n",
    "\n",
    "import seqlogo\n",
    "\n",
    "import copy\n",
    "\n",
    "### Set random seed\n",
    "seed = 5\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('hw3_data.csv', dtype = str, delimiter = ',')[1:]\n",
    "peptide = data[:,2]\n",
    "\n",
    "def create_ohe_dictionary(peptide):\n",
    "    ohe_dict = {}\n",
    "    encoding = 0\n",
    "    for i in range(len(peptide)):\n",
    "        for j in range(len(peptide[i])):\n",
    "            if peptide[i][j] not in ohe_dict.keys():\n",
    "                ohe_dict[peptide[i][j]] = encoding\n",
    "                encoding += 1\n",
    "    return ohe_dict\n",
    "\n",
    "ohe_dict = create_ohe_dictionary(peptide)\n",
    "\n",
    "def ohe_row(peptide_string, ohe_dict):\n",
    "    idx = 0\n",
    "    row = np.zeros(shape=9*len(ohe_dict))\n",
    "    for aa in peptide_string:\n",
    "        row[idx + ohe_dict[aa]] = 1\n",
    "        idx += len(ohe_dict)\n",
    "    return row\n",
    "\n",
    "def one_hot_encoding(peptide, ohe_dict):\n",
    "    ohe_encoding_peptide = np.zeros(shape=(len(peptide), 9 * len(ohe_dict)))\n",
    "    for i in range(len(peptide)):\n",
    "        ohe_encoding_peptide[i] = ohe_row(peptide[i], ohe_dict)\n",
    "    return ohe_encoding_peptide\n",
    "\n",
    "X = one_hot_encoding(peptide, ohe_dict)\n",
    "y = data[:,3].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/2000]\tR2 train:\t-0.8543\tR2 test:\t-0.8299\n",
      "[100/2000]\tR2 train:\t0.2774\tR2 test:\t0.2764\n",
      "[200/2000]\tR2 train:\t0.4214\tR2 test:\t0.4013\n",
      "[300/2000]\tR2 train:\t0.4382\tR2 test:\t0.4211\n",
      "[400/2000]\tR2 train:\t0.4588\tR2 test:\t0.4219\n",
      "[500/2000]\tR2 train:\t0.4977\tR2 test:\t0.4487\n",
      "[600/2000]\tR2 train:\t0.5131\tR2 test:\t0.4607\n",
      "[700/2000]\tR2 train:\t0.5428\tR2 test:\t0.4846\n",
      "[800/2000]\tR2 train:\t0.5514\tR2 test:\t0.4857\n",
      "[900/2000]\tR2 train:\t0.5723\tR2 test:\t0.5055\n",
      "[1000/2000]\tR2 train:\t0.5999\tR2 test:\t0.5242\n",
      "[1100/2000]\tR2 train:\t0.6053\tR2 test:\t0.5190\n",
      "[1200/2000]\tR2 train:\t0.6048\tR2 test:\t0.5210\n",
      "[1300/2000]\tR2 train:\t0.6174\tR2 test:\t0.5301\n",
      "[1400/2000]\tR2 train:\t0.6215\tR2 test:\t0.5293\n",
      "[1500/2000]\tR2 train:\t0.6275\tR2 test:\t0.5224\n",
      "[1600/2000]\tR2 train:\t0.6378\tR2 test:\t0.5215\n",
      "[1700/2000]\tR2 train:\t0.6502\tR2 test:\t0.5275\n",
      "[1800/2000]\tR2 train:\t0.6631\tR2 test:\t0.5336\n",
      "[1900/2000]\tR2 train:\t0.6703\tR2 test:\t0.5337\n",
      "R2 train:\t 0.6786\n",
      "R2 test:\t 0.5397\n"
     ]
    }
   ],
   "source": [
    "# RandomForestRegressor with random query\n",
    "X_train_random = copy.deepcopy(X_train)\n",
    "y_train_random = copy.deepcopy(y_train)\n",
    "\n",
    "regressor = ActiveLearner(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    query_strategy=uncertainty_sampling,\n",
    "    X_training=X_train_random[0].reshape(1, -1), \n",
    "    y_training=y_train_random[np.array(0)].reshape(1),\n",
    ")\n",
    "n_queries = 2000\n",
    "for idx in range(n_queries):\n",
    "    query_idx = np.random.randint(len(X_train_random))\n",
    "    regressor.teach(X_train_random[query_idx].reshape(1, -1), y_train_random[np.array(query_idx)].reshape(1))\n",
    "    X_train_random, y_train_random = (np.delete(X_train_random, query_idx, axis=0), np.delete(y_train_random, query_idx))\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        y_pred_final = regressor.predict(X_test)\n",
    "        y_train_pred = regressor.predict(X_train)\n",
    "        r2_test = r2_score(y_test, y_pred_final)\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        print(\"[%d/%d]\\tR2 train:\\t%.4f\\tR2 test:\\t%.4f\" %(idx, n_queries, r2_train, r2_test))\n",
    "    \n",
    "y_pred_final = regressor.predict(X_test)\n",
    "y_train_pred = regressor.predict(X_train)\n",
    "r2_test = r2_score(y_test,y_pred_final)\n",
    "r2_train = r2_score(y_train,y_train_pred)\n",
    "\n",
    "# print(y_test,y_pred_final,y_train_pred)\n",
    "print(\"R2 train:\\t %.4f\" %(r2_train))\n",
    "print(\"R2 test:\\t %.4f\" %(r2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/2000]\tR2 train:\t-1.6069\tR2 test:\t-1.5795\n",
      "[100/2000]\tR2 train:\t0.1704\tR2 test:\t0.1232\n",
      "[200/2000]\tR2 train:\t0.1088\tR2 test:\t0.0704\n",
      "[300/2000]\tR2 train:\t0.3947\tR2 test:\t0.3574\n",
      "[400/2000]\tR2 train:\t0.4907\tR2 test:\t0.4531\n",
      "[500/2000]\tR2 train:\t0.5065\tR2 test:\t0.4732\n",
      "[600/2000]\tR2 train:\t0.5356\tR2 test:\t0.5005\n",
      "[700/2000]\tR2 train:\t0.5474\tR2 test:\t0.5137\n",
      "[800/2000]\tR2 train:\t0.5790\tR2 test:\t0.5485\n",
      "[900/2000]\tR2 train:\t0.5865\tR2 test:\t0.5541\n",
      "[1000/2000]\tR2 train:\t0.5934\tR2 test:\t0.5636\n",
      "[1100/2000]\tR2 train:\t0.6058\tR2 test:\t0.5766\n",
      "[1200/2000]\tR2 train:\t0.6131\tR2 test:\t0.5811\n",
      "[1300/2000]\tR2 train:\t0.6164\tR2 test:\t0.5841\n",
      "[1400/2000]\tR2 train:\t0.6243\tR2 test:\t0.5906\n",
      "[1500/2000]\tR2 train:\t0.6280\tR2 test:\t0.5961\n",
      "[1600/2000]\tR2 train:\t0.6325\tR2 test:\t0.6007\n",
      "[1700/2000]\tR2 train:\t0.6329\tR2 test:\t0.5994\n",
      "[1800/2000]\tR2 train:\t0.6367\tR2 test:\t0.6031\n",
      "[1900/2000]\tR2 train:\t0.6390\tR2 test:\t0.6038\n",
      "R2 train:\t 0.6404\n",
      "R2 test:\t 0.6048\n"
     ]
    }
   ],
   "source": [
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# activeGaussianProcessRegressor with active sampling\n",
    "X_train_active = X_train.copy()\n",
    "y_train_active = y_train.copy()\n",
    "\n",
    "kernel = DotProduct(sigma_0=1.5)+WhiteKernel()\n",
    "\n",
    "learners = [\n",
    "    ActiveLearner(\n",
    "        estimator=GaussianProcessRegressor(kernel = kernel),\n",
    "        X_training=X_train_active[idx].reshape(1, -1), \n",
    "        y_training=y_train_active[np.array(idx)].reshape(1),\n",
    "    ) for idx in range(4)\n",
    "]\n",
    "committee = CommitteeRegressor(\n",
    "    learner_list = learners,\n",
    "    query_strategy = max_std_sampling,\n",
    ")\n",
    "\n",
    "n_queries = 2000\n",
    "for idx in range(n_queries):\n",
    "    query_idx,_ = committee.query(X_train_active)\n",
    "    committee.teach(X_train_active[query_idx].reshape(1, -1), y_train_active[np.array(query_idx)].reshape(1))\n",
    "    X_train_active, y_train_active = (np.delete(X_train_active, query_idx, axis=0), np.delete(y_train_active, query_idx))\n",
    "    \n",
    "    if idx % 100 == 0:\n",
    "        y_pred_final = committee.predict(X_test, return_std = False)\n",
    "        y_train_pred = committee.predict(X_train, return_std = False)\n",
    "        r2_test = r2_score(y_test, y_pred_final)\n",
    "        r2_train = r2_score(y_train, y_train_pred)\n",
    "        print(\"[%d/%d]\\tR2 train:\\t%.4f\\tR2 test:\\t%.4f\" %(idx, n_queries, r2_train, r2_test))\n",
    "    \n",
    "y_pred_final = committee.predict(X_test, return_std = False)\n",
    "y_train_pred = committee.predict(X_train, return_std = False)\n",
    "r2_test = r2_score(y_test, y_pred_final)\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# print(y_test,y_pred_final,y_train_pred)\n",
    "print(\"R2 train:\\t %.4f\" %(r2_train))\n",
    "print(\"R2 test:\\t %.4f\" %(r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1. Done (see code)\n",
    "2. Done (see code)\n",
    "3. We use committee regressor. It contains three guassian process regressor using a combination of DotProduct and WhiteKernel. Each regressor intializes with different training samples.\n",
    "4. Active Learner: $R^2 = 0.6048$. Number of n_queries = 2000\n",
    "5. Random Forest regressor with random query: $R^2 = 0.5337$. Number of n_queries = 2000\n",
    "6. Comparison:\n",
    "With same amount of training data (2000 queries), committee regressor achieves higher $R^2$ score than random forest regressor with random query. Random forest regressor has a higher $R^2$ score than committee regressor. However, when number of queries increase, committee regressor outperforms random forest regressor. \n",
    "\n",
    "Within the first 1000 queries, random forest regressor achieves $R^2 = 0.5999$ in training set and $R^2 = 0.5242$ in test set. However, the final $R^2 = 0.6703$ in training set and $R^2 = 0.5337$ in test set. It implies that in 1000-2000 queries, random forest regressor begins the overfit the training data and there is no large improvement of $R^2$ in test set.\n",
    "\n",
    "Within the first 1000 queries, committee regressor achieves $R^2 =0.5934$ in training set and $R^2 = 0.5636$ in test set. It behaves better than random forest regressor in test set. It finally achieves is $R^2 = 0.6390$ in training set and $R^2 = 0.6038$ in test set. We notice that compared to random forest regressor, committee regressor has a higher $R^2$ in test set and a lower $R^2$ in training set. During queries 1000-2000, committee regressor continues to achieves higher $R^2$ in test set which means that it does learn something.\n",
    "\n",
    "Therefore, from comparison above, committee regressor with active learning achieves higher $R^2$ in the same amount of queries than random forest regressor with random query. It also reduces overfitting of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
