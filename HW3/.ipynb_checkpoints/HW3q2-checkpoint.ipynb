{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (50 points)\n",
    "In this question, you will simulate a peptide design experiment, trying to find peptides with high binding affinity to MHC class I using a bayesian optimization approach. Notice the goal here is not trying to find a peptide sequence that maximize the binding affinity to MHC, Since a sizable proportion of the sequence data we are using contains maximum binding affinity out of the data (9.0). Using the same feature encoding as question 1, we will examine several techniques to maximize the percentage of sequence with affinity of 9.0 for stringent querying.\n",
    "\n",
    "$\\textbf{Complete the code under ###TO DO in each cell and produce the required plots.}$ Feel free to define any helper functions as you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "from modAL.models import BayesianOptimizer\n",
    "from modAL.acquisition import max_EI\n",
    "\n",
    "import seqlogo\n",
    "\n",
    "import copy\n",
    "\n",
    "### Set randome seed\n",
    "seed = 5\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Processing the DataÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('hw3_data.csv', dtype = str, delimiter = ',')[1:]\n",
    "### TO DO\n",
    "peptide = data[:,2]\n",
    "encode_order = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "def create_ohe_dictionary(encode_order):\n",
    "    ohe_dict = {}\n",
    "    encoding = 0\n",
    "    for i in range(len(encode_order)):\n",
    "        ohe_dict[encode_order[i]] = encoding\n",
    "        encoding += 1\n",
    "    return ohe_dict\n",
    "\n",
    "ohe_dict = create_ohe_dictionary(encode_order)\n",
    "\n",
    "def ohe_row(peptide_string, ohe_dict):\n",
    "    idx = 0\n",
    "    row = np.zeros(shape=9*len(ohe_dict))\n",
    "    for aa in peptide_string:\n",
    "        row[idx + ohe_dict[aa]] = 1\n",
    "        idx += len(ohe_dict)\n",
    "    return row\n",
    "\n",
    "def one_hot_encoding(peptide, ohe_dict):\n",
    "    ohe_encoding_peptide = np.zeros(shape=(len(peptide), 9 * len(ohe_dict)))\n",
    "    for i in range(len(peptide)):\n",
    "        ohe_encoding_peptide[i] = ohe_row(peptide[i], ohe_dict)\n",
    "    return ohe_encoding_peptide\n",
    "\n",
    "X = one_hot_encoding(peptide, ohe_dict)\n",
    "y = data[:,3].astype('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1: Random Sampling (5 pts. total) \n",
    "\n",
    "Create a random query strategy for randomly selecting a sample to query from the data. If the data selected is a new sequence with binding affnity of 9.0, append it to a list. After each query selection, measure the percentage of sequence with binding affnity 9.0 found by the strategy. Do this for 200 sampling steps. This will serve as the baseline to compare with optimizator performance in section 2.2 and 2.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cp = copy.deepcopy(X)\n",
    "y_cp = copy.deepcopy(y)\n",
    "optimal_idx_rand = []\n",
    "history_rand = []\n",
    "cnt = 0\n",
    "### TO DO\n",
    "n_query = 200\n",
    "for i in range(n_query):\n",
    "    idx = np.random.randint(0, len(y_cp))\n",
    "    if y_cp[idx] == 9.0:\n",
    "        cnt += 1\n",
    "        optimal_idx_rand.append(X_cp[idx])    \n",
    "    history_rand.append(cnt / (i+1))\n",
    "    X_cp, y_cp = np.delete(X_cp, idx, axis=0), np.delete(y_cp, idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2: Baysian Optimization with Gaussian Process (15 pts. total)\n",
    "\n",
    "Create a Baysian optimizer with Gaussian process as regressor and Max Expected improvement as the queuing strategy. If the data selected is a new sequence with binding affinity of 9.0, append it to a list. After each query selection, measure the percentage of sequence with binding affinity 9.0 found by the strategy. Do this for 200 sampling steps. \n",
    "\n",
    "$\\textbf{Hint}$: Check the <a href=\"https://modal-python.readthedocs.io/en/latest/content/examples/bayesian_optimization.html#Optimizing-using-expected-improvement\"> modAL documentation</a> for how to set up a Baysian optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cp = copy.deepcopy(X)\n",
    "y_cp = copy.deepcopy(y)\n",
    "\n",
    "optimal_idx_gp = []\n",
    "history_gp = []\n",
    "arr = np.arange(len(X_cp))\n",
    "np.random.shuffle(arr)\n",
    "### TO DO\n",
    "# initializing the optimizer\n",
    "optimizer = BayesianOptimizer(\n",
    "    estimator=GaussianProcessRegressor(),\n",
    "    X_training=X_cp[arr[:10]],\n",
    "    y_training=y_cp[arr[:10]],\n",
    "    query_strategy=max_EI\n",
    ")\n",
    "# Bayesian optimization\n",
    "cnt = 0\n",
    "\n",
    "for i in range(n_query):\n",
    "    query_idx, query_inst = optimizer.query(X_cp)\n",
    "    optimizer.teach(X_cp[query_idx].reshape(1, -1), y_cp[np.array(query_idx)].reshape(1))\n",
    "    if y_cp[query_idx] == 9.0:\n",
    "        cnt += 1\n",
    "        optimal_idx_gp.append(X_cp[query_idx])    \n",
    "    history_gp.append(cnt / (i+1))\n",
    "    X_cp, y_cp = np.delete(X_cp, query_idx, axis=0), np.delete(y_cp, query_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3: Bayesian Optimizer with Random Forest (10 pts. total)\n",
    "\n",
    "Although Baysian optimization often uses the Gaussian process, Baysian optimizer in ModAL can take any other regressor that has a predict function with a return_std input parameter. If return_std is set to True, the function returns the predicted values and standard deviation in the prediction. Create a Baysian optimizer with random forest regressor and Max Expected improvement as the queuing strategy. If the data selected is a new sequence with binding affinity of 9.0, append it to a list. After each query selection, measure the percentage of sequences with binding affinity 9.0 found by the strategy. Do this for 200 sampling steps. \n",
    "\n",
    "$\\textbf{Hint}$: You might find the following class wrapper for random forest helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rfwapper(RandomForestRegressor):\n",
    "    def predict(self, X, return_std = False):\n",
    "        if return_std:\n",
    "            ys = np.array([e.predict(X) for e in self.estimators_])\n",
    "            return np.mean(ys, axis = 0).ravel(), (np.std(ys, axis = 0).ravel() + 1e-6)\n",
    "        return super().predict(X).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_cp = copy.deepcopy(X)\n",
    "y_cp = copy.deepcopy(y)\n",
    "\n",
    "optimal_idx_rf = []\n",
    "history_rf = []\n",
    "arr = np.arange(len(X_cp))\n",
    "np.random.shuffle(arr)\n",
    "\n",
    "### TO DO\n",
    "# initializing the optimizer\n",
    "optimizer = BayesianOptimizer(\n",
    "    estimator=rfwapper(),\n",
    "    X_training=X_cp[arr[:10]],\n",
    "    y_training=y_cp[arr[:10]],\n",
    "    query_strategy=max_EI\n",
    ")\n",
    "# Bayesian optimization\n",
    "cnt = 0\n",
    "n_query = 200\n",
    "for i in range(n_query):\n",
    "    query_idx, query_inst = optimizer.query(X_cp)\n",
    "    optimizer.teach(X_cp[query_idx].reshape(1, -1), y_cp[np.array(query_idx)].reshape(1))\n",
    "    if y_cp[query_idx] == 9.0:\n",
    "        cnt += 1\n",
    "        optimal_idx_rf.append(X_cp[query_idx])\n",
    "    history_rf.append(cnt / (i+1))\n",
    "    X_cp, y_cp = np.delete(X_cp, query_idx, axis=0), np.delete(y_cp, query_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4: Plot Percentage of sequence with maximum binding affinity with respect to number of sequence queried (10 pts. total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot our performance over time.\n",
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=130)\n",
    "\n",
    "ax.plot(history_gp)\n",
    "ax.scatter(range(len(history_gp)), history_gp, s=13, label = 'Baysian')\n",
    "\n",
    "\n",
    "ax.plot(history_rf)\n",
    "ax.scatter(range(len(history_rf)), history_rf, s=13, label = 'RF')\n",
    "\n",
    "\n",
    "ax.plot(history_rand)\n",
    "ax.scatter(range(len(history_rand)), history_rand, s=13, label = 'Random')\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "ax.set_title('Incremental classification accuracy')\n",
    "ax.set_xlabel('Query iteration')\n",
    "ax.set_ylabel('Percentage of sequence with pIC50 = 9.0')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5: Create sequence logo based on sequences found with each querying strategies (5 pts. total)\n",
    "\n",
    "A sequence logo is a graphical representation of the sequence conservation of amino acids in protein sequences), as amino acids that are important for functions are likely to be conserved. Hence, a sequence logo is a way to visualize such an importance. Convert the each sets of sequences obtained by one of your optimization strategies to a sequence logo. Below is an example using all of the sequence of affinity 9.0.\n",
    "\n",
    "\n",
    "$\\textbf{Important}$: We are using <a href=\"https://pypi.org/project/seqlogo/\"> seqlogo</a> to create sequence logo from our set of sequences. You can install seqlogo by entering the command \n",
    "\n",
    "conda install -c bioconda seqlogo \n",
    "\n",
    "in your conda terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[np.where(y == 9)[0]]\n",
    "ppm = np.sum(X_opt, axis = 0).reshape(20,9)\n",
    "ppm /= np.sum(ppm, axis = 0)\n",
    "ppm = seqlogo.Ppm(ppm, alphabet_type=\"AA\")\n",
    "seqlogo.seqlogo(ppm, ic_scale = False, format = 'jpeg', size = 'medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = optimal_idx_rf\n",
    "ppm = np.sum(X_rf, axis = 0).reshape(20,9)\n",
    "ppm /= np.sum(ppm, axis = 0)\n",
    "ppm = seqlogo.Ppm(ppm, alphabet_type=\"AA\")\n",
    "seqlogo.seqlogo(ppm, ic_scale = False, format = 'jpeg', size = 'medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
